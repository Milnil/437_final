<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Raspberry Pi AV Stream</title>
    <style>
        body {
            font-family: sans-serif;
            text-align: center;
            background: #f0f0f0;
            margin: 0;
            padding: 0;
        }

        header {
            background: #333;
            color: #fff;
            padding: 10px;
        }

        h1 {
            margin: 20px 0;
        }

        #video {
            margin-top: 20px;
            border: 2px solid #333;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        #controls {
            margin: 20px;
            padding: 20px;
            background: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .button {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
            margin: 0 10px;
            border: none;
            border-radius: 4px;
            transition: background-color 0.3s;
        }

        #startButton {
            background-color: #4CAF50;
            color: white;
        }

        #startButton:hover {
            background-color: #45a049;
        }

        #muteButton {
            background-color: #f44336;
            color: white;
        }

        #muteButton:hover {
            background-color: #da190b;
        }

        #status {
            margin: 10px 0;
            padding: 10px;
            border-radius: 4px;
        }

        .status-connected {
            background-color: #dff0d8;
            color: #3c763d;
        }

        .status-disconnected {
            background-color: #f2dede;
            color: #a94442;
        }

        #instructions {
            max-width: 600px;
            margin: 40px auto;
            text-align: left;
            background: #fff;
            padding: 20px;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }
    </style>
</head>

<body>
    <header>
        <h2>Raspberry Pi Streaming</h2>
    </header>

    <div id="controls">
        <h3>Stream Controls</h3>
        <button id="startButton" class="button">Start Stream</button>
        <button id="muteButton" class="button">Mute Audio</button>
        <div id="status">Click Start Stream to begin</div>
    </div>

    <div id="videoContainer">
        <img id="video" src="" alt="Video Stream" width="320" height="240" style="display: none;" />
    </div>

    <div id="instructions">
        <h2>Instructions:</h2>
        <ol>
            <li>Click "Start Stream" to begin both video and audio simultaneously.</li>
            <li>Use "Mute Audio" to toggle audio on/off.</li>
            <li>Check browser console for debug info.</li>
        </ol>
        <p><strong>Note:</strong> Audio playback requires direct user interaction. Ensure you click the button to start
            the stream.</p>
    </div>

    <script>
        const sampleRate = 16000;
        const channels = 1;
        const bytesPerSample = 2;
        let audioContext;
        let processor;
        let muted = false;
        let buffer = new Uint8Array(0);
        let streaming = false;

        const startButton = document.getElementById('startButton');
        const muteButton = document.getElementById('muteButton');
        const videoElement = document.getElementById('video');
        const statusDiv = document.getElementById('status');

        startButton.addEventListener('click', () => {
            if (!streaming) {
                streaming = true;
                startButton.textContent = 'Stop Stream';
                statusDiv.textContent = 'Connecting...';
                statusDiv.className = '';

                // User gesture: create and resume audio context here
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate });
                    console.log("AudioContext created:", audioContext);
                }

                // Resume immediately in user gesture to allow audio playback
                audioContext.resume().then(() => {
                    console.log("AudioContext resumed");
                });

                // Set up ScriptProcessorNode
                processor = audioContext.createScriptProcessor(4096, 0, channels);
                processor.connect(audioContext.destination);
                processor.onaudioprocess = handleAudioProcess;

                // Start video first
                videoElement.style.display = 'block';
                videoElement.src = '/video';
                console.log("Video stream started:", videoElement.src);

                // Start audio fetch in parallel (no await)
                startAudioFetch().then(() => {
                    console.log("Audio stream ended normally.");
                }).catch(err => {
                    console.error("Audio stream error:", err);
                    if (streaming) {
                        statusDiv.textContent = 'Error: Audio stream failed';
                        statusDiv.className = 'status-disconnected';
                    }
                });

                statusDiv.textContent = 'Connected: Streaming audio and video';
                statusDiv.className = 'status-connected';

            } else {
                // Stop streaming
                streaming = false;
                startButton.textContent = 'Start Stream';

                // Stop video
                videoElement.style.display = 'none';
                videoElement.src = '';

                // Close audio context if open
                if (audioContext && audioContext.state !== 'closed') {
                    audioContext.close().then(() => {
                        console.log("AudioContext closed");
                        audioContext = null;
                    });
                }

                buffer = new Uint8Array(0);
                statusDiv.textContent = 'Stream stopped';
                statusDiv.className = '';
                console.log("Streaming stopped.");
            }
        });

        muteButton.addEventListener('click', () => {
            muted = !muted;
            muteButton.textContent = muted ? 'Unmute Audio' : 'Mute Audio';
            console.log(`Audio is now ${muted ? 'muted' : 'unmuted'}`);
        });

        function handleAudioProcess(audioEvent) {
            const output = audioEvent.outputBuffer.getChannelData(0);
            const neededSamples = output.length;
            const neededBytes = neededSamples * bytesPerSample;

            if (muted || buffer.length < neededBytes) {
                output.fill(0);
                if (!muted && buffer.length < neededBytes) {
                    console.log(`Buffer underrun: have ${buffer.length} bytes, need ${neededBytes} bytes`);
                }
                return;
            }

            const chunk = buffer.slice(0, neededBytes);
            buffer = buffer.slice(neededBytes);

            const dataView = new DataView(chunk.buffer);
            for (let i = 0; i < neededSamples; i++) {
                let sample = dataView.getInt16(i * 2, true);
                output[i] = sample / 32768.0;
            }
        }

        async function startAudioFetch() {
            console.log("Fetching audio stream...");
            const response = await fetch('/audio');
            if (!response.ok) throw new Error('Failed to fetch audio stream');

            console.log("Connected to audio stream");
            const reader = response.body.getReader();

            while (streaming) {
                const { value, done } = await reader.read();
                if (done) {
                    console.log("No more audio data from server.");
                    break;
                }
                if (value) {
                    let newBuffer = new Uint8Array(buffer.length + value.length);
                    newBuffer.set(buffer, 0);
                    newBuffer.set(value, buffer.length);
                    buffer = newBuffer;
                }
            }
        }
    </script>
</body>

</html>