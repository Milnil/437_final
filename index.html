<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Raspberry Pi MJPEG + PCM Audio</title>
    <style>
        body {
            font-family: sans-serif;
            text-align: center;
            background: #f0f0f0;
            margin: 0;
            padding: 0;
        }

        header {
            background: #333;
            color: #fff;
            padding: 10px;
        }

        h1 {
            margin: 20px 0;
        }

        #video {
            margin-top: 20px;
            border: 2px solid #333;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        #controls {
            margin: 20px;
        }

        #muteButton {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
        }

        #instructions {
            max-width: 600px;
            margin: 40px auto;
            text-align: left;
            background: #fff;
            padding: 20px;
            border-radius: 4px;
        }
    </style>
</head>

<body>
    <header>
        <h2>Raspberry Pi Streaming</h2>
    </header>

    <h1>Live Video and Audio</h1>
    <img id="video" src="/video" alt="Video Stream" width="320" height="240" />

    <div id="controls">
        <h3>Audio Controls</h3>
        <button id="muteButton">Mute</button>
    </div>

    <div id="instructions">
        <h2>Notes:</h2>
        <p>This page shows an MJPEG video and uses the Web Audio API to play raw PCM audio from the Raspberry Pi in
            real-time.</p>
        <p>If the audio is not heard, ensure that your browser supports the required features and that you've allowed
            autoplay (or interacted with the page to allow sound).</p>
    </div>

    <script>
        // Audio settings must match the server
        const sampleRate = 16000;
        const channels = 1;
        const bytesPerSample = 2; // 16-bit PCM
        let audioContext;
        let sourceNode;
        let processor;
        let audioStreamPaused = false;
        let muted = false;

        const muteButton = document.getElementById('muteButton');
        muteButton.addEventListener('click', () => {
            muted = !muted;
            if (muted) {
                muteButton.textContent = 'Unmute';
            } else {
                muteButton.textContent = 'Mute';
            }
        });

        async function startAudio() {
            // Create AudioContext once user interacts (for autoplay policies)
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }

            // Create a ScriptProcessorNode
            // Note: ScriptProcessorNode is deprecated, but still widely supported.
            // A more modern approach would use an AudioWorkletNode.
            processor = audioContext.createScriptProcessor(4096, 0, channels);
            processor.onaudioprocess = (audioEvent) => {
                // We'll fill this with PCM data from the stream.
                // This callback is driven by the audio system pulling data from the node.
            };

            processor.connect(audioContext.destination);

            // Fetch and stream audio data
            const response = await fetch('/audio');
            if (!response.ok) {
                console.error('Failed to fetch audio stream');
                return;
            }

            const reader = response.body.getReader();

            let buffer = new Uint8Array(0);

            // We'll push data from the network into the audio node when needed.
            processor.onaudioprocess = (audioEvent) => {
                if (muted || audioStreamPaused) {
                    // Fill with silence
                    let output = audioEvent.outputBuffer.getChannelData(0);
                    output.fill(0);
                    return;
                }

                let output = audioEvent.outputBuffer.getChannelData(0);
                let neededSamples = output.length; // Float32 samples
                let neededBytes = neededSamples * bytesPerSample;

                // Ensure we have enough data in buffer
                if (buffer.length < neededBytes) {
                    // Not enough data available yet, fill with silence
                    output.fill(0);
                    return;
                }

                // Extract neededBytes from buffer
                const chunk = buffer.slice(0, neededBytes);
                buffer = buffer.slice(neededBytes);

                // Convert from 16-bit PCM to float
                const dataView = new DataView(chunk.buffer);
                for (let i = 0; i < neededSamples; i++) {
                    let sample = dataView.getInt16(i * 2, true);
                    output[i] = sample / 32768.0;
                }
            };

            // Continuously read data from the stream and append to our buffer
            while (true) {
                const { value, done } = await reader.read();
                if (done) break;
                if (value) {
                    // Append new data
                    let newBuffer = new Uint8Array(buffer.length + value.length);
                    newBuffer.set(buffer, 0);
                    newBuffer.set(value, buffer.length);
                    buffer = newBuffer;
                }
            }
        }

        // Start audio on user interaction to comply with autoplay policies.
        document.addEventListener('click', () => {
            if (!audioContext || audioContext.state !== 'running') {
                startAudio();
            }
        }, { once: true });
    </script>
</body>

</html>