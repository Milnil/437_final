<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Raspberry Pi MJPEG + PCM Audio (ScriptProcessorNode)</title>
    <style>
        body {
            font-family: sans-serif;
            text-align: center;
            background: #f0f0f0;
            margin: 0;
            padding: 0;
        }

        header {
            background: #333;
            color: #fff;
            padding: 10px;
        }

        h1 {
            margin: 20px 0;
        }

        #video {
            margin-top: 20px;
            border: 2px solid #333;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        #controls {
            margin: 20px;
        }

        #muteButton {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
        }

        #instructions {
            max-width: 600px;
            margin: 40px auto;
            text-align: left;
            background: #fff;
            padding: 20px;
            border-radius: 4px;
        }
    </style>
</head>

<body>
    <header>
        <h2>Raspberry Pi Streaming</h2>
    </header>

    <h1>Live Video and Audio</h1>
    <img id="video" src="/video" alt="Video Stream" width="320" height="240" />

    <div id="controls">
        <h3>Audio Controls</h3>
        <button id="muteButton">Mute</button>
    </div>

    <div id="instructions">
        <h2>Notes:</h2>
        <p>This page shows an MJPEG video and uses the deprecated ScriptProcessorNode to play raw PCM audio in near
            real-time.</p>
        <p>We have added console logs to verify that audio data is being received. Check your browser's JavaScript
            console for messages.</p>
        <p>Click anywhere on the page to start the audio (autoplay policies may require a user interaction).</p>
    </div>

    <script>
        const sampleRate = 16000;
        const channels = 1;
        const bytesPerSample = 2; // 16-bit PCM
        let audioContext;
        let processor;
        let muted = false;
        let buffer = new Uint8Array(0);

        const muteButton = document.getElementById('muteButton');
        muteButton.addEventListener('click', () => {
            muted = !muted;
            muteButton.textContent = muted ? 'Unmute' : 'Mute';
            console.log(`Audio is now ${muted ? 'muted' : 'unmuted'}.`);
        });

        async function startAudio() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate });
                console.log("Created new AudioContext with sampleRate:", sampleRate);
            }

            processor = audioContext.createScriptProcessor(4096, 0, channels);
            processor.connect(audioContext.destination);

            processor.onaudioprocess = (audioEvent) => {
                let output = audioEvent.outputBuffer.getChannelData(0);
                let neededSamples = output.length;
                let neededBytes = neededSamples * bytesPerSample;

                if (muted || buffer.length < neededBytes) {
                    // Not enough data or muted, fill with silence
                    output.fill(0);
                    if (!muted && buffer.length < neededBytes) {
                        console.log(`Not enough data to fill audio buffer (have ${buffer.length} bytes, need ${neededBytes} bytes).`);
                    }
                    return;
                }

                // Extract needed bytes from buffer
                const chunk = buffer.slice(0, neededBytes);
                buffer = buffer.slice(neededBytes);

                const dataView = new DataView(chunk.buffer);
                for (let i = 0; i < neededSamples; i++) {
                    let sample = dataView.getInt16(i * 2, true);
                    output[i] = sample / 32768.0;
                }
            };

            // Start fetching audio data
            console.log("Fetching audio data from /audio...");
            const response = await fetch('/audio');
            if (!response.ok) {
                console.error('Failed to fetch audio stream');
                return;
            }
            console.log("Successfully connected to /audio stream.");

            const reader = response.body.getReader();

            while (true) {
                const { value, done } = await reader.read();
                if (done) {
                    console.log("Audio stream ended.");
                    break;
                }
                if (value) {
                    console.log(`Received audio data chunk of length: ${value.length} bytes`);
                    // Append new data
                    let newBuffer = new Uint8Array(buffer.length + value.length);
                    newBuffer.set(buffer, 0);
                    newBuffer.set(value, buffer.length);
                    buffer = newBuffer;
                    console.log(`Buffer size after appending: ${buffer.length} bytes`);
                }
            }
        }

        // Start audio on user interaction (autoplay policy)
        document.addEventListener('click', () => {
            if (!audioContext || audioContext.state !== 'running') {
                console.log("User clicked on the page. Starting audio...");
                startAudio();
            }
        }, { once: true });
    </script>
</body>

</html>